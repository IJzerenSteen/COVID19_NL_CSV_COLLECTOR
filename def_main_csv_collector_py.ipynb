{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "def_main_csv_collector.py",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "wOcFfFQp6vyt",
        "colab_type": "code",
        "outputId": "6664914a-b9fc-4e49-a8b1-83139e4dcda0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        }
      },
      "source": [
        "#########################################################################################################################\n",
        "#                                        COVID-19 DATA COLLECTOR FOR NETHERLANDS                                        #\n",
        "# This is a part of a project. The collector scraps data via BS4 from RIVM and ECDC's websites, wrangle and manipulate  #\n",
        "# the data convert them to a dataframe and save it as csv file. The csv files refresh themselves through main function  #\n",
        "# every certain time. So,they will keep up to date data. April 2020  github/IjzerenSteen                                #\n",
        "#########################################################################################################################\n",
        "\n",
        "#Importing relevant library \n",
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "import pandas as pd\n",
        "import threading\n",
        "import time\n",
        "from datetime import date, datetime, timedelta\n",
        "\n",
        "#For using Google Drive path & Saving data to Google Drive \n",
        "from google.colab import drive\n",
        "drive.mount('drive')\n",
        "\n",
        "def main():\n",
        "    t = threading.Timer(21600, main) #21600 - 6 hours\n",
        "    t.start() \n",
        "    rivm_data1()\n",
        "    rivm_data2()\n",
        "    rivm_data3()\n",
        "    rivm_data4()\n",
        "    ecdc_data()\n",
        "    print('1')\n",
        "    \n",
        "def rivm_data1():\n",
        "    '''Total Cases and Deaths Numbers\n",
        "    via RIVM.NL website'''\n",
        "    \n",
        "    #Scrapping the data via BS4\n",
        "    request_data1=requests.get('https://www.rivm.nl/coronavirus-kaart-van-nederland').text\n",
        "    soup1 = BeautifulSoup(request_data1,'html.parser')\n",
        "    my_table1=soup1.find_all('table')\n",
        "    \n",
        "    #Scrapping the data via BS4\n",
        "    request_data1=requests.get('https://www.rivm.nl/coronavirus-kaart-van-nederland').text\n",
        "    soup1 = BeautifulSoup(request_data1,'html.parser')\n",
        "    my_table1=soup1.find_all('table')\n",
        "    \n",
        "    #Setting the data to a dataframe\n",
        "    my_table1[0]=str(my_table1[0]).replace('*','')\n",
        "    my_table1[0]=str(my_table1[0]).replace('\\n','')\n",
        "    my_table1[0]=str(my_table1[0]).replace(')','')\n",
        "    my_table1[0]=str(my_table1[0]).replace('(','')\n",
        "    my_table1[0]=str(my_table1[0]).replace('+','')\n",
        "    my_table1[0]=str(my_table1[0]).replace('.','')    \n",
        "    df1= pd.read_html(str(my_table1[0]), index_col=False, header=None)[0]\n",
        "    df1=df1.T\n",
        "    df1.drop(df1.index[0],inplace=True)\n",
        "\n",
        "    #Cleaning the data\n",
        "    headers=[\"People tested positive\", \"Admitted to Hospital\", \"Death\"]\n",
        "    df1.columns=headers\n",
        "\n",
        "    df1[\"People tested positive daily increase\"]=df1[\"People tested positive\"][2]\n",
        "    df1[\"Admitted to Hospital daily increase\"]=df1[\"Admitted to Hospital\"][2]\n",
        "    df1[\"Death daily increase\"]=df1[\"Death\"][2]\n",
        "    df1.drop(2,0,inplace=True)\n",
        "\n",
        "    df1[\"People tested positive\"]= pd.to_numeric(df1[\"People tested positive\"], downcast='integer')\n",
        "    df1[\"Admitted to Hospital\"] = pd.to_numeric(df1[\"Admitted to Hospital\"], downcast='integer')\n",
        "    df1[\"Death\"] = pd.to_numeric(df1[\"Death\"], downcast='integer')\n",
        "    df1[\"People tested  daily increase\"]= pd.to_numeric(df1[\"People tested positive daily increase\"], downcast='integer')\n",
        "    df1[\"Admitted to Hospital daily increase\"] = pd.to_numeric(df1[\"Admitted to Hospital daily increase\"], downcast='integer')\n",
        "    df1[\"Death daily increase\"] = pd.to_numeric(df1[\"Death daily increase\"], downcast='integer')\n",
        "\n",
        "    #Seave it to a csv file to a certain path\n",
        "    df1.to_csv (r'/content/drive/My Drive/NLP proje/Our codings/Data Analysis/CSV/rivm_data_1_total.csv',  index = True, header=True)\n",
        "\n",
        "def rivm_data2():\n",
        "    '''Daily data of Hospitalized and Reported patients,\n",
        "    and Death Numbers through Rivm.nl website'''\n",
        "    \n",
        "    # Scrapping the 3 csv data from rivm.nl\n",
        "    request_data=requests.get('https://www.rivm.nl/coronavirus-covid-19/grafieken').text\n",
        "    soup = BeautifulSoup(request_data,'html.parser')\n",
        "    my_table=soup.find_all('script', {'type':\"application/json\"})\n",
        "    my_table=str(my_table)\n",
        "    my_table=my_table.split(\"csv\")\n",
        "\n",
        "    #Dataset1\n",
        "    #Data cleaning \n",
        "    table_1 = my_table[4]\n",
        "    table_1 = table_1.replace('\\\\u0022', '')\n",
        "    table_1 = table_1.split(\"data:\")[0]\n",
        "    table_1 = str(table_1).split(']\",\"pre')[0]\n",
        "    table_1 = str(table_1).split(\"ren],\")[1]\n",
        "    table_1 = table_1.replace(\"]\", '')\n",
        "    table_1 = table_1.split(\"[\")\n",
        "\n",
        "    #Setting the data to a data frame \n",
        "    df1 = pd.DataFrame([sub.split(\",\") for sub in table_1 ])\n",
        "    df1.drop([3], axis=1, inplace=True)\n",
        "    df1.drop(0,inplace=True)\n",
        "    df1.columns=[\"day_month\",\"Reported_New_Cases\",\"Reported_Previous_Cases\"]\n",
        "\n",
        "    #Changing the numerical columns from string to integer and adding a total column \n",
        "    df1.Reported_New_Cases = pd.to_numeric(df1.Reported_New_Cases, downcast='integer')\n",
        "    df1.Reported_Previous_Cases = pd.to_numeric(df1.Reported_Previous_Cases, downcast='integer')\n",
        "    df1.loc[:,\"Reported_Total_Cases\"] = df1.Reported_New_Cases + df1.Reported_Previous_Cases\n",
        "\n",
        "    #Setting the date data to date form of pandas library\n",
        "    df1['Year']= '2020'\n",
        "    df1['date']=df1.day_month+' '+ df1.Year\n",
        "    df1.date=df1.date.str.replace(\"mrt\",\"mar\")\n",
        "    df1.date=df1.date.str.replace(\"mei\",\"may\")\n",
        "    df1.date=pd.to_datetime(df1.date).dt.date\n",
        "    df1.drop(['day_month'], axis=1, inplace=True)\n",
        "    df1.drop(['Year'], axis=1, inplace=True)\n",
        "    df1 = df1[['date', 'Reported_New_Cases', 'Reported_Previous_Cases', 'Reported_Total_Cases']]\n",
        "    #df1.to_csv (r'/content/drive/My Drive/NLP proje/Our codings/Data Analysis/CSV/data_rivm_reported.csv',  index = True, header=True)\n",
        "\n",
        "    #Dataset2\n",
        "    #Data cleaning process \n",
        "    table_2 = my_table[3]\n",
        "    table_2 = table_2.replace('\\\\u0022', '')\n",
        "    table_2 = table_2.split(\"data:\")[0]\n",
        "    table_2 = table_2.split(']\",\"pre')[0]\n",
        "    table_2 = table_2.split(\"ren],\")[1]\n",
        "    table_2 = table_2.replace(\"]\", '')\n",
        "    table_2 = table_2.split(\"[\")\n",
        "    \n",
        "    #Setting the data to a data frame \n",
        "    df2 = pd.DataFrame([sub.split(\",\") for sub in table_2 ])\n",
        "    df2.drop([3], axis=1, inplace=True)\n",
        "    df2.drop(0,inplace=True)\n",
        "    df2.columns=[\"day_month\",\"Hospitalized_New_Cases\",\"Hospitalized_Previous_Cases\"]\n",
        "    \n",
        "    #Changing the numerical columns from string to integer and adding a total column \n",
        "    df2.Hospitalized_New_Cases = pd.to_numeric(df2.Hospitalized_New_Cases, downcast='integer')\n",
        "    df2.Hospitalized_Previous_Cases = pd.to_numeric(df2.Hospitalized_Previous_Cases, downcast='integer')\n",
        "    df2.loc[:,\"Hospitalized_Total_Cases\"] = df2.Hospitalized_New_Cases + df2.Hospitalized_Previous_Cases\n",
        "\n",
        "    #Setting the date data to date form of pandas library\n",
        "    df2['Year']= '2020'\n",
        "    df2['date']=df2.day_month+' '+ df2.Year\n",
        "    df2.date=df2.date.str.replace(\"mrt\",\"mar\")\n",
        "    df2.date=df2.date.str.replace(\"mei\",\"may\")\n",
        "    df2.date=pd.to_datetime(df2.date).dt.date\n",
        "    df2.drop(['day_month'], axis=1, inplace=True)\n",
        "    df2.drop(['Year'], axis=1, inplace=True)\n",
        "    df2 = df2[['date', 'Hospitalized_New_Cases', 'Hospitalized_Previous_Cases', 'Hospitalized_Total_Cases']]\n",
        "    #df2.to_csv (r'/content/drive/My Drive/NLP proje/Our codings/Data Analysis/CSV/data_rivm_hospitalized.csv',  index = True, header=True)\n",
        "\n",
        "    #Dataset3\n",
        "    #Data cleaning process \n",
        "    table_3 = my_table[2]\n",
        "    table_3 = table_3.replace('\\\\u0022', '')\n",
        "    table_3 = table_3.split(\"data:\")[0]\n",
        "    table_3 = str(table_3).split(']\",\"pre')[0]\n",
        "    table_3 = str(table_3).split(\"ren],\")[1]\n",
        "    table_3 = table_3.replace(\"]\", '')\n",
        "    table_3 = table_3.split(\"[\")\n",
        "\n",
        "    #Setting the data to a data frame \n",
        "    df3 = pd.DataFrame([sub.split(\",\") for sub in table_3 ])\n",
        "    df3.drop([3], axis=1, inplace=True)\n",
        "    df3.drop(0,inplace=True)\n",
        "    df3.columns=[\"day_month\",\"New_Cases\",\"Previous_Cases\"]\n",
        "\n",
        "    #Setting the date data to date form for pandas library\n",
        "    df3.New_Cases = pd.to_numeric(df3.New_Cases, downcast='integer')\n",
        "    df3.Previous_Cases = pd.to_numeric(df3.Previous_Cases, downcast='integer')\n",
        "    df3.loc[:,\"Deaths\"] = df3.New_Cases + df3.Previous_Cases\n",
        "\n",
        "    #Setting the date data to date form of pandas library\n",
        "    df3['Year']= '2020'\n",
        "    df3['date']=df3.day_month+' '+ df3.Year\n",
        "    df3.date=df3.date.str.replace(\"mrt\",\"mar\")\n",
        "    df3.date=df3.date.str.replace(\"mei\",\"may\")\n",
        "    df3.date=pd.to_datetime(df3.date).dt.date\n",
        "    df3.drop(['day_month'], axis=1, inplace=True)\n",
        "    df3.drop(['Year'], axis=1, inplace=True)\n",
        "    df3 = df3[['date', 'New_Cases', 'Previous_Cases', 'Deaths']]\n",
        "    #df3.to_csv (r'data_rivm_death.csv',  index = True, header=True)\n",
        "    \n",
        "    #Merging 3 datasets to a data frame\n",
        "    df_merged0=pd.merge(df1,df2[['date', 'Hospitalized_New_Cases', 'Hospitalized_Previous_Cases', 'Hospitalized_Total_Cases']], on='date', how=\"left\") #Left join\n",
        "    df_merged=pd.merge(df_merged0,df3[['date', 'New_Cases', 'Previous_Cases', 'Deaths']], on='date', how=\"left\") #Left join\n",
        "    df_merged['Country']='Netherlands'\n",
        "    \n",
        "    #Save the dataframe as csv file to a certain path\n",
        "    df_merged.to_csv (r'/content/drive/My Drive/NLP proje/Our codings/Data Analysis/CSV/rivm_data_2_reported_hospitalized_deaths.csv',  index = True, header=True)\n",
        "\n",
        "def rivm_data3():\n",
        "    \"\"\"PART 1 - The numbers of cases by municipality through rivm.nl\n",
        "    PART 2 - The data of provinces from wikipedia\n",
        "    PART 3 - Merging in a dataframe of both datasets\"\"\"\n",
        "\n",
        "    #Part-1\n",
        "    #Scrapping the data from rivm.nl \n",
        "    request_data=requests.get('https://www.rivm.nl/coronavirus-kaart-van-nederland').text\n",
        "    soup = BeautifulSoup(request_data,'html.parser')\n",
        "    my_table=soup.find_all('div', {'id':\"csvData\"})\n",
        "    table=str(my_table[0]).split('\\n')\n",
        "\n",
        "    #Setting it to a dataframe \n",
        "    df2 = pd.DataFrame([sub.split(\";\") for sub in table ])\n",
        "\n",
        "    #Cleaning the data \n",
        "    df2.drop(0,0,inplace=True)\n",
        "    df2.drop(1,0,inplace=True)\n",
        "    df2.dropna(inplace=True)\n",
        "    df2.drop(df2.tail(0).index,0,inplace=True)\n",
        "    df2.drop([0,6,7,8], 1, inplace=True)\n",
        "    headers=[\"Municipality\",\"Reported_Case_Number\",\"Hospitalized_Case_Number\",\"Death\",\"Population\"]\n",
        "    df2.columns=headers\n",
        "    df2['Population'] = pd.to_numeric(df2['Population'], downcast='integer')\n",
        "    df2['Reported_Case_Number'] = pd.to_numeric(df2['Reported_Case_Number'], downcast='integer')\n",
        "    df2['Hospitalized_Case_Number'] = pd.to_numeric(df2['Hospitalized_Case_Number'], downcast='integer')\n",
        "    df2['Death'] = pd.to_numeric(df2['Death'], downcast='integer')\n",
        "\n",
        "    #PART-2 \n",
        "    #Scrapping the data from wikipedia\n",
        "    request_data2 = requests.get('https://simple.wikipedia.org/wiki/List_of_municipalities_of_the_Netherlands').text\n",
        "    soup2 = BeautifulSoup(request_data2,'html.parser')\n",
        "    my_table2 = soup2.find_all('table')\n",
        "    \n",
        "    #Setting it to a dataframe\n",
        "    df3 = pd.read_html(str(my_table2))[1]\n",
        "\n",
        "    #PART-3\n",
        "    #Merging the both datasets in a dataframe \n",
        "    df=pd.merge(df2,df3[['Municipality','Province']], on='Municipality', how=\"left\") #Left join\n",
        "    \n",
        "    #Filling the null provinces & Cleaning the data\n",
        "    df.loc[df['Municipality']=='West Betuwe', 'Province']='Gelderland'\n",
        "    df.loc[df['Municipality']=='Westerkwartier', 'Province']='Groningen'\n",
        "    df.loc[df['Municipality']=='Vijfheerenlanden', 'Province']='Utrecht'\n",
        "    df.loc[df['Municipality']=='s-Gravenhage', 'Province']='South Holland'\n",
        "    df.loc[df['Municipality']=='Noardeast-Fryslân', 'Province']='Friesland'\n",
        "    df.loc[df['Municipality']=='Mill en Sint Hubert', 'Province']='North Brabant'\n",
        "    df.loc[df['Municipality']=='Hoeksche Waard', 'Province']='South Holland'\n",
        "    df.loc[df['Municipality']=='Het Hogeland', 'Province']='Groningen'\n",
        "    df.loc[df['Municipality']=='Bergen (NH.)', 'Province']=' North Holland'\n",
        "    df.loc[df['Municipality']=='Bergen (L.)', 'Province']='Limburg'\n",
        "    df.loc[df['Municipality']=='Beekdaelen', 'Province']='Limburg'\n",
        "    df.loc[df['Municipality']=='Altena', 'Province']='North Brabant'\n",
        "    df.loc[df['Municipality']=='Molenlanden', 'Province']='South Holland'\n",
        "    df.loc[df['Municipality']=='Noardeast-FryslÃ¢n', 'Municipality']='Noardeast-Fryslan'\n",
        "    df.loc[df['Municipality']=='Noardeast-Fryslan', 'Province']='Friesland'\n",
        "    df.loc[df['Municipality']=='SÃºdwest-FryslÃ¢n', 'Municipality']='Sudwest-Fryslan'\n",
        "    df.loc[df['Municipality']=='Sudwest-Fryslan', 'Province']='Friesland'\n",
        "    df.Province=df.Province.str.lstrip()\n",
        "    \n",
        "    #Saving the data to csv file in a certian path\n",
        "    df.to_csv (r'/content/drive/My Drive/NLP proje/Our codings/Data Analysis/CSV/rivm_data_3_prov_mun.csv',  index = True, header=True)\n",
        "    \n",
        "def rivm_data4():\n",
        "    '''Age & gender distirbution of \n",
        "    deaths due to Covid-19 disease \n",
        "    from rivm.nl'''\n",
        "    \n",
        "    # Scrapping the data from rivm.nl\n",
        "    request_data=requests.get('https://www.rivm.nl/coronavirus-covid-19/grafieken').text\n",
        "    soup = BeautifulSoup(request_data,'html.parser')\n",
        "    my_table=soup.find_all('script', {'type':\"application/json\"})\n",
        "    my_table=str(my_table)\n",
        "    my_table=my_table.split(\"csv\")\n",
        "    \n",
        "    #Data Wrangling\n",
        "    table_4 = my_table[1]\n",
        "    table_4 = table_4.replace('\\\\u0022', '')\n",
        "    table_4 = table_4.split(\"data:\")[0]\n",
        "    table_4 = str(table_4).split(']\",\"pre')[0]\n",
        "    table_4 = table_4.replace(\"]\", '')\n",
        "    table_4 = table_4.split(\"[\")\n",
        "    \n",
        "    #Setting the date to a data frame & Cleaning the data \n",
        "    df4 = pd.DataFrame([sub.split(\",\") for sub in table_4])\n",
        "    df4.drop([3], axis=1, inplace=True)\n",
        "    df4.drop([0,1,2],inplace=True)\n",
        "    df4.columns=[\"Age\",\"Male\",\"Female\"]\n",
        "    df4.Male = pd.to_numeric(df4.Male)\n",
        "    df4.Female = pd.to_numeric(df4.Female)\n",
        "    df4.loc[:,\"Total\"] = df4.Male + df4.Female\n",
        "    df4['Country']='Netherlands'\n",
        "    \n",
        "    #Saving the data to csv file in a certian path\n",
        "    df4.to_csv (r'/content/drive/My Drive/NLP proje/Our codings/Data Analysis/CSV/rivm_data_4_gender_age_NL.csv',  index = True, header=True)\n",
        "    \n",
        "def ecdc_data():\n",
        "\n",
        "    '''COVID-19 Cases and Deaths \n",
        "    data for the Netherlands \n",
        "    through ECDC website -\n",
        "    daily updated excel file'''\n",
        "\n",
        "    #Scrapping excel data via BS4 from ECDC & Setting the data to a dataframe\n",
        "    today = datetime.now()\n",
        "    today = today.strftime('%Y-%m-%d')\n",
        "    yesterday = datetime.now() - timedelta(days=1)\n",
        "    yesterday = yesterday.strftime('%Y-%m-%d')\n",
        "\n",
        "    try: \n",
        "        url=f'https://www.ecdc.europa.eu/sites/default/files/documents/COVID-19-geographic-disbtribution-worldwide-{today}.xlsx'\n",
        "        df_s = pd.read_excel(url, parse_date=[0],index_col=0)#Parsing date is for time series analysis  \n",
        "        df_domain = pd.DataFrame(df_s)\n",
        "    \n",
        "    except:    \n",
        "        url=f'https://www.ecdc.europa.eu/sites/default/files/documents/COVID-19-geographic-disbtribution-worldwide-{yesterday}.xlsx'\n",
        "        df_s = pd.read_excel(url, parse_date=[0],index_col=0)#Parsing date is for time series analysis  \n",
        "        df_domain = pd.DataFrame(df_s)\n",
        "        \n",
        "    #Data Wrangling\n",
        "    df_domain.columns = ['Day','Month','Year','Cases','Deaths', 'Countries_and_territories','GeoId','Country_Code','Population','Continent']\n",
        "    df_domain.drop('Day',1,inplace=True)\n",
        "    df_domain.drop('Month',1,inplace=True)\n",
        "    df_domain.drop('Year',1,inplace=True)\n",
        "    df_domain.drop('Countries_and_territories',1,inplace=True)\n",
        "    df_domain.drop('Country_Code',1,inplace=True)\n",
        "    df_domain.drop('Population',1,inplace=True)\n",
        "    df_domain.drop('Continent',1, inplace=True)\n",
        "    df_domain = df_domain[df_domain['GeoId'] == 'NL']\n",
        "    df_domain.drop('GeoId',1,inplace=True)\n",
        "    df_domain.drop(df_domain.tail(1).index,inplace=True) # drop last row 31-12-2019\n",
        "    df_domain['Case_Fatality_Ratio'] =df_domain.Deaths/df_domain.Cases\n",
        "    \n",
        "    #Saving the data to csv file in a certian path\n",
        "    df_domain.to_csv (r'/content/drive/My Drive/NLP proje/Our codings/Data Analysis/CSV/ECDC_data_case_deaths.csv',  index = True, header=True)\n",
        "\n",
        "\n",
        "    \n",
        "main()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at drive\n",
            "1\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
